{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374be5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 04:02:28.454595: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 04:02:28.698866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-20 04:02:28.698886: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-20 04:02:30.075673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-20 04:02:30.076166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-20 04:02:30.076179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11230 images belonging to 6 classes.\n",
      "Found 2804 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 04:02:41.309759: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-20 04:02:41.310044: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-20 04:02:41.310085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kali): /proc/driver/nvidia/version does not exist\n",
      "2022-12-20 04:02:41.310869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 04:02:41.438809: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 17334272 exceeds 10% of free system memory.\n",
      "2022-12-20 04:02:41.447035: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 17334272 exceeds 10% of free system memory.\n",
      "2022-12-20 04:02:41.450943: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 17334272 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 04:02:43.130069: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 15360000 exceeds 10% of free system memory.\n",
      "2022-12-20 04:02:43.585792: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 17334272 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 437s 1s/step - loss: 1.2143 - categorical_accuracy: 0.5352 - val_loss: 1.0225 - val_categorical_accuracy: 0.6277\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 355s 1s/step - loss: 0.9237 - categorical_accuracy: 0.6460 - val_loss: 0.8437 - val_categorical_accuracy: 0.6844\n",
      "Epoch 3/10\n",
      " 64/351 [====>.........................] - ETA: 4:41 - loss: 0.8198 - categorical_accuracy: 0.7043"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = 'seg_train/seg_train'\n",
    "class_names = os.listdir(base_dir)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   validation_split=0.2\n",
    "                                   )\n",
    "validation_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "image_size = (200, 200)\n",
    "training_set = train_datagen.flow_from_directory(base_dir,\n",
    "                                                 seed=101,                                                 \n",
    "                                                 target_size=image_size,\n",
    "                                                 batch_size=32,\n",
    "                                                 subset = \"training\",\n",
    "                                                 class_mode='categorical')\n",
    "validation_set = validation_gen.flow_from_directory(base_dir, \n",
    "                                               target_size=image_size,\n",
    "                                               batch_size=32, \n",
    "                                               subset = \"validation\",\n",
    "                                               class_mode='categorical')\n",
    "\n",
    "model = Sequential([\n",
    "            \n",
    "    Conv2D(filters=32,kernel_size=(3,3),  input_shape = (200, 200, 3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=32,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(filters=64,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "history = model.fit(training_set,validation_data=validation_set, epochs=10,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11344dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab5e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70a6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
